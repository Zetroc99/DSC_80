{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 06\n",
    "\n",
    "### Due Date: Tuesday May 11th, 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab*.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab**.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab**.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab**.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab**.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab**.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab**` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab06 as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic HTML tags practice\n",
    "\n",
    "**Question 1**\n",
    "\n",
    "Create a very basic `html` file that satisfies the following properties:\n",
    "\n",
    "1. Has `<head>` and `<body>` tags.\n",
    "2. Has a title\n",
    "3. Inside the body tags:\n",
    "    * At least two headers\n",
    "    * At least three images:\n",
    "        * At least one image must be a local file;\n",
    "        * At least one image must be linked to online source; \n",
    "        * At least one image has to have default text when it cannot be displayed.\n",
    "    * At least three references (hyperlinks) to different web pages;\n",
    "    * At least one table with two columns.\n",
    "    \n",
    "        \n",
    "   \n",
    "4. Save your work as `lab06_1.html` in the same directory as `lab06.py`, make sure it loads in the browser and do not forget to submit it.\n",
    "5. **Do not forget to submit all data files needed to display your page.**\n",
    "\n",
    "**Note:** You can toy with (basic) HTML in the cells of a notebook, using either a \"markdown cell\" or by using the `IPython.display.HTML` function. However, be sure to open your saved file in a browser to be sure the page displays properly!\n",
    "\n",
    "**Note:** If you work within Jupyter Notebook, you can later copy your text into a text editor and save it with the .html extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping an Online Bookstore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Browse through the following fake on-line bookstore: http://books.toscrape.com/. This website is meant for toying with scraping.\n",
    "\n",
    "Scrape the website, collecting data on all books that have **at least a four-star rating**, with a price **under £50** and belong to the book categories you want. You should collect the data in a dataframe as below (if you get an encoding error on your prices columns, like you see in the table below, don't worry about it):\n",
    "<img src=\"data/bookdata.png\">\n",
    "\n",
    "\n",
    "Do this using the following steps:\n",
    "1. Create a function `extract_book_links` that takes in the content of a book-listing page (a string of html), and returns a list of urls of book-detail pages that satisfy the requirements on \"*at least* a four-star rating, and prices are *under* £50\". \n",
    "\n",
    "2. Create a function `get_product_info` that takes in the content of a book-detail page (a string of html), a variable `categories` that is a list of book categories you want. If this input book is in the categories you want, returns a dictionary corresponding to a row in the dataframe in the image above (where the keys are the column names and the values are the row values); else, skip this book since this is not the book you want (ie. return None).\n",
    "\n",
    "3. Create a function `scrape_books` of a single variable `k` that scrapes the first `k` pages of the bookstore (as determined by starting at the url above and clicking on the 'next' button),a variable `categories` that is a list of book categories you want, and returns a dataframe of books as the picture above. (Note: make sure the books returned satisfy the requirements set in part 1 about rating and price).\n",
    "\n",
    "\n",
    "*Note:* Your function should take under 180 seconds to run through the entire bookstore.\n",
    "\n",
    "*Note:* Don't worry about type casting (ie changing number of reviews to an int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'products.html')\n",
    "text = open(fp, encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = bs4.BeautifulSoup(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seven-brief-lessons-on-physics_219/index.html',\n",
       " 'scarlet-the-lunar-chronicles-2_218/index.html',\n",
       " 'saga-volume-3-saga-collected-editions-3_216/index.html',\n",
       " 'running-with-scissors_215/index.html',\n",
       " 'rise-of-the-rocket-girls-the-women-who-propelled-us-from-missiles-to-the-moon-to-mars_213/index.html',\n",
       " 'ready-player-one_209/index.html']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.extract_book_links(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'Frankenstein.html')\n",
    "text = open(fp, encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_2 = lab.get_product_info(text,['Default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.4 s ± 376 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "lab.scrape_books(49, ['Romance', 'Mystery'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Requests\n",
    "**Question 3**\n",
    "\n",
    "You trade stocks as a hobby. As an avid pandas coder, you figured it is best to calculate some statistics by pulling data from a public API (https://financialmodelingprep.com/developer/docs/#Stock-Historical-Price). Specifically, \"Historical price with change and volume interval\".\n",
    "\n",
    "Some definitions (these are the ones you need to know):\n",
    "- open: The opening price of a stock at the beginning of a trading day\n",
    "- close: The closing price of a stock at the end of a trading day\n",
    "- volume: The total number of shares being traded in a day\n",
    "- percent change: difference in price with respect to the original price (in percentages)\n",
    "\n",
    "\n",
    "1. Create a function `stock_history` which takes in the stock code (`ticker`) as a string, `year` and `month` as integers, and return a dataframe which has the price history for that stock in that month (include all columns).\n",
    "\n",
    "2. Create a function `stock_stats` that takes in the output dataframe from `stock_history` and output the stock price change as a percentage and a rough total transaction volume **in billion dollars** for that month. Assume that on average, shares are traded at the midpoint price of high and low for that day. Return these two values as a tuple in a readable format: reserve 2 decimal points for both values and add a plus or minus sign at the front of the percent change. \n",
    "$$ \\text{Total Transaction Volume (in dollars)} = \\text{Volume (number of shares traded)} \\times \\text{Price} $$\n",
    "\n",
    "*Example*: If \\\\$BYND opens at \\\\$80 and closes at \\\\$120 with a volume of 1 million, its percent change for the day is $(\\$120-\\$80) \\div \\$80 = +50.00\\%$. And the estimated total transaction volume is: $(\\$80+\\$120) / 2 \\times 10^6 = 0.10\\text{B}$.\n",
    "\n",
    "\n",
    "Hint: [pd.date_range](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html), \n",
    "\n",
    "*Note:* Make sure you read the API documentation if you get stuck!\n",
    "\n",
    "*Note 2:* In order to make successful requests, you will need an API key. In order to get one, you will need to sign up to the website. Once signed up, you can use the API key that comes with the free plan. It has a limit of 250 requests per day, which should be more than enough. In the code below, replace `your_key` when making requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_1 = lab.stock_history('AAPL', 2019, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('+12.71%', '99.05B')"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_2 = lab.stock_stats(q3_1)\n",
    "q3_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment Threads\n",
    "\n",
    "**Question 4**\n",
    "\n",
    "As a hacker, you get your daily dose of tech news on [Hacker News](https://news.ycombinator.com/). The problem now is that you don't have internet access on your phone in your morning commute to work, so you want to save the interesting stories' comments thread beforehand in a flat file source like csv. You find their API documentation ( https://github.com/HackerNews/API) and implement the following task:\n",
    "\n",
    "1. Write a function `get_comments` that takes `storyid` as a parameter and returns a dataframe of all the comments below the news story. You can ignore 'dead' comments (you will know it when you see it). **Make sure the order of the comments in your dataframe is from top to bottom just as you see on the website**. You are allowed to use loops in this function. Addtional requirement: write at least one helper method\n",
    "\n",
    "You only want these information for the comments:\n",
    "1. `id`: the unique ids\n",
    "2. `by`: the author of the comment\n",
    "3. `parent`: who (also in unique ids) they are replying to\n",
    "4. `text`: the actual comment\n",
    "5. `time`: when the comment is created (in `pd.datetime` format)\n",
    "\n",
    "Hints:\n",
    "1. Use depth-first-search when traversing the comments tree.\n",
    "2. https://docs.python.org/3/tutorial/datastructures.html#using-lists-as-stacks.\n",
    "3. Check the size of your dataframe to the story's `descendants` attribute (number of comments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "storyid = 18344932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_endpoint = f\"https://hacker-news.firebaseio.com/v0/item/{storyid}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(news_endpoint).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'by': 'ScottWRobinson',\n",
       " 'descendants': 18,\n",
       " 'id': 18344932,\n",
       " 'kids': [18380397,\n",
       "  18346406,\n",
       "  18348601,\n",
       "  18346750,\n",
       "  18346476,\n",
       "  18346746,\n",
       "  18346388],\n",
       " 'score': 47,\n",
       " 'time': 1540987334,\n",
       " 'title': 'TimescaleDB 1.0 Is Production Ready',\n",
       " 'type': 'story',\n",
       " 'url': 'https://blog.timescale.com/1-0-enterprise-production-ready-time-series-database-open-source-d32395a10cbf'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = response\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Invalid path: Invalid token in path'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_id = response['kids']\n",
    "ep = f\"https://hacker-news.firebaseio.com/v0/item/{next_id}.json\"\n",
    "res = requests.get(ep).json()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "def dfs(graph, data=None, q = None):\n",
    "    if q is None:\n",
    "        q = deque()\n",
    "    if 'dead' in graph:\n",
    "        q.append(graph)\n",
    "    if 'kids' in graph:\n",
    "        users = graph['kids']     \n",
    "        q.append(graph)\n",
    "        for user_id in users:\n",
    "            end_point = f\"https://hacker-news.firebaseio.com/v0/item/{user_id}.json\"\n",
    "            new_graph = requests.get(end_point).json()\n",
    "            dfs(new_graph, data, q)\n",
    "            q.append(new_graph)\n",
    "    if 'dead' not in graph:\n",
    "        data.append(q.popleft())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs(graph, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>parent</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18380397</td>\n",
       "      <td>valyala</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>TimescaleDB is great for storing time series c...</td>\n",
       "      <td>1541400799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18346406</td>\n",
       "      <td>msiggy</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>I&amp;#x27;m excited to give this database a try i...</td>\n",
       "      <td>1540999222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18348601</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>Can this be used side by side on normal Postgr...</td>\n",
       "      <td>1541014179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18348631</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18348601.0</td>\n",
       "      <td>Yep, absolutely. Regular PostgreSQL tables coe...</td>\n",
       "      <td>1541014492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18348984</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18348631.0</td>\n",
       "      <td>Good to hear! how does the current TimescaleDB...</td>\n",
       "      <td>1541017426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18349540</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18348984.0</td>\n",
       "      <td>Not sure I follow exactly what you&amp;#x27;re ask...</td>\n",
       "      <td>1541022440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18350673</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18349540.0</td>\n",
       "      <td>Alright thanks! I thought I read that Timescal...</td>\n",
       "      <td>1541034719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18351061</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18350673.0</td>\n",
       "      <td>It does not support sharding writes across mul...</td>\n",
       "      <td>1541039703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18350673</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18349540.0</td>\n",
       "      <td>Alright thanks! I thought I read that Timescal...</td>\n",
       "      <td>1541034719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18349540</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18348984.0</td>\n",
       "      <td>Not sure I follow exactly what you&amp;#x27;re ask...</td>\n",
       "      <td>1541022440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18348984</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18348631.0</td>\n",
       "      <td>Good to hear! how does the current TimescaleDB...</td>\n",
       "      <td>1541017426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18348631</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18348601.0</td>\n",
       "      <td>Yep, absolutely. Regular PostgreSQL tables coe...</td>\n",
       "      <td>1541014492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18348601</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>Can this be used side by side on normal Postgr...</td>\n",
       "      <td>1541014179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18346750</td>\n",
       "      <td>zip1234</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>How fast is it when it has a TB of data? I rea...</td>\n",
       "      <td>1541001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18347260</td>\n",
       "      <td>nevi-me</td>\n",
       "      <td>18346750.0</td>\n",
       "      <td>I spent about 8 months writing data to TSDB. I...</td>\n",
       "      <td>1541004454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18347555</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>18346750.0</td>\n",
       "      <td>They have some numbers on their blog. Its very...</td>\n",
       "      <td>1541006374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18346750</td>\n",
       "      <td>zip1234</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>How fast is it when it has a TB of data? I rea...</td>\n",
       "      <td>1541001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18346476</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>I evaluated this heavily but had to backoff be...</td>\n",
       "      <td>1540999649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          by      parent  \\\n",
       "0   18380397     valyala  18344932.0   \n",
       "1   18346406      msiggy  18344932.0   \n",
       "2   18348601     sman393  18344932.0   \n",
       "3   18348631  RobAtticus  18348601.0   \n",
       "4   18348984     sman393  18348631.0   \n",
       "5   18349540  RobAtticus  18348984.0   \n",
       "6   18350673     sman393  18349540.0   \n",
       "7   18351061  RobAtticus  18350673.0   \n",
       "8   18350673     sman393  18349540.0   \n",
       "9   18349540  RobAtticus  18348984.0   \n",
       "10  18348984     sman393  18348631.0   \n",
       "11  18348631  RobAtticus  18348601.0   \n",
       "12  18348601     sman393  18344932.0   \n",
       "13  18346750     zip1234  18344932.0   \n",
       "14  18347260     nevi-me  18346750.0   \n",
       "15  18347555    dominotw  18346750.0   \n",
       "16  18346750     zip1234  18344932.0   \n",
       "17  18346476    dominotw  18344932.0   \n",
       "\n",
       "                                                 text        time  \n",
       "0   TimescaleDB is great for storing time series c...  1541400799  \n",
       "1   I&#x27;m excited to give this database a try i...  1540999222  \n",
       "2   Can this be used side by side on normal Postgr...  1541014179  \n",
       "3   Yep, absolutely. Regular PostgreSQL tables coe...  1541014492  \n",
       "4   Good to hear! how does the current TimescaleDB...  1541017426  \n",
       "5   Not sure I follow exactly what you&#x27;re ask...  1541022440  \n",
       "6   Alright thanks! I thought I read that Timescal...  1541034719  \n",
       "7   It does not support sharding writes across mul...  1541039703  \n",
       "8   Alright thanks! I thought I read that Timescal...  1541034719  \n",
       "9   Not sure I follow exactly what you&#x27;re ask...  1541022440  \n",
       "10  Good to hear! how does the current TimescaleDB...  1541017426  \n",
       "11  Yep, absolutely. Regular PostgreSQL tables coe...  1541014492  \n",
       "12  Can this be used side by side on normal Postgr...  1541014179  \n",
       "13  How fast is it when it has a TB of data? I rea...  1541001103  \n",
       "14  I spent about 8 months writing data to TSDB. I...  1541004454  \n",
       "15  They have some numbers on their blog. Its very...  1541006374  \n",
       "16  How fast is it when it has a TB of data? I rea...  1541001103  \n",
       "17  I evaluated this heavily but had to backoff be...  1540999649  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data).iloc[1:].reset_index().filter(items = ['id', 'by', 'parent', 'text', 'time'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = df['time'].apply(lambda x: pd.to_datetime(x, unit='s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>parent</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9224</td>\n",
       "      <td>BrandonM</td>\n",
       "      <td>8863.0</td>\n",
       "      <td>I have a few qualms with this app:&lt;p&gt;1. For a ...</td>\n",
       "      <td>2007-04-05 15:16:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9272</td>\n",
       "      <td>dhouston</td>\n",
       "      <td>9224.0</td>\n",
       "      <td>1. re: the first part, many people want someth...</td>\n",
       "      <td>2007-04-05 16:47:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9479</td>\n",
       "      <td>BrandonM</td>\n",
       "      <td>9272.0</td>\n",
       "      <td>You are correct that this presents a very good...</td>\n",
       "      <td>2007-04-06 01:39:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9272</td>\n",
       "      <td>dhouston</td>\n",
       "      <td>9224.0</td>\n",
       "      <td>1. re: the first part, many people want someth...</td>\n",
       "      <td>2007-04-05 16:47:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9224</td>\n",
       "      <td>BrandonM</td>\n",
       "      <td>8863.0</td>\n",
       "      <td>I have a few qualms with this app:&lt;p&gt;1. For a ...</td>\n",
       "      <td>2007-04-05 15:16:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>9353</td>\n",
       "      <td>dhouston</td>\n",
       "      <td>9324.0</td>\n",
       "      <td>couple of clarifications :)&lt;p&gt;1) i have other ...</td>\n",
       "      <td>2007-04-05 19:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>9324</td>\n",
       "      <td>vlad</td>\n",
       "      <td>9205.0</td>\n",
       "      <td>I totally missed that.  I just know he was int...</td>\n",
       "      <td>2007-04-05 18:42:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>9205</td>\n",
       "      <td>zkinion</td>\n",
       "      <td>9097.0</td>\n",
       "      <td>I'm guessing he did, though I may be wrong.  T...</td>\n",
       "      <td>2007-04-05 14:54:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>9097</td>\n",
       "      <td>vlad</td>\n",
       "      <td>9067.0</td>\n",
       "      <td>I don't know if he applied; he has tried befor...</td>\n",
       "      <td>2007-04-05 06:41:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>9067</td>\n",
       "      <td>zkinion</td>\n",
       "      <td>8863.0</td>\n",
       "      <td>It looks great man.  I know you'll be accepted...</td>\n",
       "      <td>2007-04-05 05:11:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        by  parent                                               text  \\\n",
       "0   9224  BrandonM  8863.0  I have a few qualms with this app:<p>1. For a ...   \n",
       "1   9272  dhouston  9224.0  1. re: the first part, many people want someth...   \n",
       "2   9479  BrandonM  9272.0  You are correct that this presents a very good...   \n",
       "3   9272  dhouston  9224.0  1. re: the first part, many people want someth...   \n",
       "4   9224  BrandonM  8863.0  I have a few qualms with this app:<p>1. For a ...   \n",
       "..   ...       ...     ...                                                ...   \n",
       "66  9353  dhouston  9324.0  couple of clarifications :)<p>1) i have other ...   \n",
       "67  9324      vlad  9205.0  I totally missed that.  I just know he was int...   \n",
       "68  9205   zkinion  9097.0  I'm guessing he did, though I may be wrong.  T...   \n",
       "69  9097      vlad  9067.0  I don't know if he applied; he has tried befor...   \n",
       "70  9067   zkinion  8863.0  It looks great man.  I know you'll be accepted...   \n",
       "\n",
       "                  time  \n",
       "0  2007-04-05 15:16:54  \n",
       "1  2007-04-05 16:47:01  \n",
       "2  2007-04-06 01:39:04  \n",
       "3  2007-04-05 16:47:01  \n",
       "4  2007-04-05 15:16:54  \n",
       "..                 ...  \n",
       "66 2007-04-05 19:42:55  \n",
       "67 2007-04-05 18:42:08  \n",
       "68 2007-04-05 14:54:19  \n",
       "69 2007-04-05 06:41:28  \n",
       "70 2007-04-05 05:11:36  \n",
       "\n",
       "[71 rows x 5 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.get_comments(8863)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
